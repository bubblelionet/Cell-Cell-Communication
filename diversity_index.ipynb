{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'graph_tool', 'wurlitzer', 'bayanpy', 'infomap'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'pyclustering', 'ASLPAw'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'wurlitzer', 'infomap'}\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import csv\n",
    "import pickle\n",
    "import matplotlib\n",
    "import math\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "from cdlib import algorithms\n",
    "from cdlib import NodeClustering\n",
    "import altair as alt\n",
    "import sys\n",
    "sys.path.append(\"/Users/victoriagao/Documents/MSc/Schwartz_lab/altair-themes/\")\n",
    "if True:  # In order to bypass isort when saving\n",
    "    import altairThemes\n",
    "\n",
    "spot_diameter = 89.43 #pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessDf(df):\n",
    "  \"\"\"Transform ligand and receptor columns.\"\"\"\n",
    "  df[\"ligand-receptor\"] = df[\"ligand\"] + '-' + df[\"receptor\"]\n",
    "  df[\"component\"] = df[\"component\"] #.astype(str).str.zfill(2)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gene_ids\n",
    "gene_ids = []\n",
    "with open(\"/Users/victoriagao/local_docs/NEST/stored_variables/gene_ids.txt\", 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove trailing newline characters and any leading/trailing whitespaces\n",
    "        line = line.strip()\n",
    "        gene_ids.append(line)\n",
    "\n",
    "# Load coordinates\n",
    "coordinates = np.load(\"/Users/victoriagao/local_docs/NEST/stored_variables/coordinates.npy\")\n",
    "\n",
    "# Load cell_barcode\n",
    "with open('/Users/victoriagao/local_docs/NEST/stored_variables/cell_barcode.pkl', 'rb') as file:\n",
    "    cell_barcode = pickle.load(file)\n",
    "\n",
    "# Load connected_components (assume already have it)\n",
    "with open(\"/Users/victoriagao/local_docs/NEST/stored_variables/filtered_connected_components.pkl\", 'rb') as file:\n",
    "    filtered_connected_components = pickle.load(file)\n",
    "\n",
    "# Load pathologist's label\n",
    "data_name = 'PDAC_64630'\n",
    "if data_name == 'PDAC_64630':\n",
    "    pathologist_label_file='/Users/victoriagao/local_docs/NEST/IX_annotation_artifacts_PDAC64630.csv' #IX_annotation_artifacts.csv' #\n",
    "    pathologist_label=[]\n",
    "    with open(pathologist_label_file) as file:\n",
    "        csv_file = csv.reader(file, delimiter=\",\")\n",
    "        for line in csv_file:\n",
    "            pathologist_label.append(line)\t\n",
    "    \t\n",
    "    barcode_type=dict() # record the type (annotation) of each spot (barcode)\n",
    "    for i in range (1, len(pathologist_label)):\n",
    "        barcode_type[pathologist_label[i][0]] = pathologist_label[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_str = 'NEST_combined_output_PDAC_64630'+'.csv'\n",
    "inputFile = '/Users/victoriagao/local_docs/NEST/output/From_Fatema/'+filename_str\n",
    "df = pd.read_csv(inputFile, sep=\",\")\n",
    "csv_record_final = df.values.tolist()\n",
    "df_column_names = list(df.columns)\n",
    "csv_record_final = [df_column_names] + csv_record_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### i.e. making a list of Dictionary to store matched records for each region\n",
    "matched_records_set_lib = {}  \n",
    "\n",
    "for set_index, connected_comp_set in enumerate(filtered_connected_components):\n",
    "    matched_records = []\n",
    "\n",
    "    for record in csv_record_final:\n",
    "        from_cell, to_cell = record[0], record[1]\n",
    "        if (from_cell in connected_comp_set) and (to_cell in connected_comp_set):\n",
    "            matched_records.append(record)\n",
    "    \n",
    "    # Store matched records for this set index in the dictionary\n",
    "    matched_records_set_lib[set_index+1] = matched_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For set 1\n",
      "Shannon-Wiener Diversity Index (H'): 3.2846\n",
      "Hill number of order 1: 26.6979\n",
      "For set 2\n",
      "Shannon-Wiener Diversity Index (H'): 1.4942\n",
      "Hill number of order 1: 4.4557\n",
      "For set 3\n",
      "Shannon-Wiener Diversity Index (H'): 3.5169\n",
      "Hill number of order 1: 33.6791\n",
      "For set 4\n",
      "Shannon-Wiener Diversity Index (H'): 3.1094\n",
      "Hill number of order 1: 22.4073\n",
      "For set 5\n",
      "Shannon-Wiener Diversity Index (H'): 3.3757\n",
      "Hill number of order 1: 29.2451\n",
      "For set 6\n",
      "Shannon-Wiener Diversity Index (H'): -0.0000\n",
      "Hill number of order 1: 1.0000\n",
      "For set 7\n",
      "Shannon-Wiener Diversity Index (H'): 2.5062\n",
      "Hill number of order 1: 12.2586\n",
      "For set 8\n",
      "Shannon-Wiener Diversity Index (H'): 1.2425\n",
      "Hill number of order 1: 3.4641\n",
      "For set 9\n",
      "Shannon-Wiener Diversity Index (H'): -0.0000\n",
      "Hill number of order 1: 1.0000\n",
      "For set 10\n",
      "Shannon-Wiener Diversity Index (H'): -0.0000\n",
      "Hill number of order 1: 1.0000\n",
      "For set 11\n",
      "Shannon-Wiener Diversity Index (H'): -0.0000\n",
      "Hill number of order 1: 1.0000\n",
      "For set 12\n",
      "Shannon-Wiener Diversity Index (H'): -0.0000\n",
      "Hill number of order 1: 1.0000\n",
      "For set 13\n",
      "Shannon-Wiener Diversity Index (H'): 2.2539\n",
      "Hill number of order 1: 9.5244\n",
      "For set 14\n",
      "Shannon-Wiener Diversity Index (H'): 0.6931\n",
      "Hill number of order 1: 2.0000\n",
      "For set 15\n",
      "Shannon-Wiener Diversity Index (H'): -0.0000\n",
      "Hill number of order 1: 1.0000\n",
      "For set 16\n",
      "Shannon-Wiener Diversity Index (H'): 0.6931\n",
      "Hill number of order 1: 2.0000\n",
      "For set 17\n",
      "Shannon-Wiener Diversity Index (H'): -0.0000\n",
      "Hill number of order 1: 1.0000\n",
      "For set 18\n",
      "Shannon-Wiener Diversity Index (H'): 0.6931\n",
      "Hill number of order 1: 2.0000\n",
      "For set 19\n",
      "Shannon-Wiener Diversity Index (H'): -0.0000\n",
      "Hill number of order 1: 1.0000\n",
      "For set 20\n",
      "Shannon-Wiener Diversity Index (H'): -0.0000\n",
      "Hill number of order 1: 1.0000\n",
      "For set 21\n",
      "Shannon-Wiener Diversity Index (H'): -0.0000\n",
      "Hill number of order 1: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Calculate Hill number q=1 for all 21 regions\n",
    "\n",
    "import math\n",
    "\n",
    "columns = ['from_cell','to_cell','ligand','receptor','attention_score','component','from_id','to_id']\n",
    "\n",
    "hill_number_data = []\n",
    "\n",
    "for key, value in matched_records_set_lib.items():\n",
    "    df_matched = pd.DataFrame(value, columns=columns)\n",
    "    df_matched_processed = preprocessDf(df_matched)\n",
    "    ligand_receptor_counts = df_matched_processed['ligand-receptor'].value_counts()\n",
    "    count_df = pd.DataFrame({'ligand-receptor': ligand_receptor_counts.index, 'count': ligand_receptor_counts.values})\n",
    "    # print(count_df)\n",
    "    # Summing\n",
    "    total_counts = count_df['count'].sum()\n",
    "    # Calculate the proportions\n",
    "    count_df['proportion'] = count_df['count'] / total_counts\n",
    "    # Calculate the Shannon-Wiener Diversity Index (H')\n",
    "    shannon_entropy = -(count_df['proportion'] * count_df['proportion'].apply(math.log)).sum()\n",
    "    # Calculate the Hill number (effective number of types) for q = 1\n",
    "    hill_number_q1 = math.exp(shannon_entropy)\n",
    "    # Print or display the calculated Shannon-Wiener Diversity Index\n",
    "    print(\"For set \"+str(key))\n",
    "    print(\"Shannon-Wiener Diversity Index (H'): {:.4f}\".format(shannon_entropy))\n",
    "    print(\"Hill number of order 1: {:.4f}\".format(hill_number_q1))\n",
    "\n",
    "    hill_number_data.append({'Set': key, 'Hill_number_q1': hill_number_q1}) # putting the hill numbers into a list\n",
    "    \n",
    "# Create a DataFrame from the collected data\n",
    "hill_number_df = pd.DataFrame(hill_number_data)\n",
    "hill_number_dict = hill_number_df.set_index('Set')['Hill_number_q1'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
